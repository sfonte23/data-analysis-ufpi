{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disciplina de Análise de Dados    \n",
    "### Curso de Gestão de Dados\n",
    "### Universidade Federal do Piauí\n",
    "##### Prof. Arlino Magalhães\n",
    "arlino@ufpi.edu.br | @arlino.magalhaes\n",
    "\n",
    "\n",
    "# Extraindo Dados da _Internet_\n",
    "\n",
    "Referência: Grus, Joel. Data Science do Zero. Capítulo 9. Disponível em: Minha Biblioteca, Editora Alta Books, 2021. \n",
    "| Link da Minha Biblioteca: https://integrada.minhabiblioteca.com.br/books/9788550816463"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As páginas da *web* são escritas em HTML, uma linguagem em que o texto (idealmente) é \n",
    "marcado em elementos e atributos:\n",
    "\n",
    "    <html> \n",
    "        <head>\n",
    "            <title>A web page</title>\n",
    "        </head>\n",
    "        <body>\n",
    "            <p id=\"author\">Joel Grus</p>\n",
    "            <p id=\"subject\">Data Science</p>\n",
    "        </body>\n",
    "    </html>\n",
    "\n",
    "Para extrair dados do HTML, usaremos a biblioteca **Beautiful Soup** (http://www.crummy.com/software/BeautifulSoup/). \n",
    "\n",
    "Também usaremos a biblioteca **Requests** (http://docs.python-requests.org/en/latest/), uma maneira mais simpática \n",
    "de fazer solicitações ao HTTP do que os recursos do Python.\n",
    "\n",
    "> `sudo pip3 install beautifulsoup4`\n",
    "\n",
    "> `pip install beautifulsoup4`\n",
    "\n",
    "\n",
    "O analisador HTML interno do Python não é muito flexível, ou seja, nem sempre processa bem o HTML com falhas na \n",
    "formação. Por isso, precisamos instalar o analisador **html5lib**. Confirme se está no ambiente virtual correto e instale as bibliotecas:\n",
    "\n",
    "> `python -m pip install beautifulsoup4 requests html5lib`\n",
    "\n",
    "O código abaixo extrai textos de página https://raw.githubusercontent.com/joelgrus/data/master/getting-data.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupera o html da página\n",
    "import requests\n",
    "\n",
    "url = (\"https://raw.githubusercontent.com/joelgrus/data/master/getting-data.html\") \n",
    "html = requests.get(url).text\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formata o html\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para encontrar a primeira tag <p> (e seu conteúdo), faça isto:\n",
    "first_paragraph = soup.find('p') # ou apenas soup.p\n",
    "first_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obter o conteúdo de texto de uma Tag, use a propriedade text:\n",
    "\n",
    "first_paragraph_text = soup.p.text\n",
    "first_paragraph_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_paragraph_words = soup.p.text.split()\n",
    "first_paragraph_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para extrair os atributos de uma tag, trate-a como um dict:\n",
    "\n",
    "first_paragraph_id = soup.p['id'] # gera KeyError se não houver ‘id’\n",
    "first_paragraph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_paragraph_id2 = soup.p.get('id') # retorna None se não houver ‘id’\n",
    "first_paragraph_id2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obter múltiplas tags ao mesmo tempo:\n",
    "\n",
    "all_paragraphs = soup.find_all('p') # ou apenas soup(‘p’)\n",
    "all_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra as tag p que possuem id\n",
    "paragraphs_with_ids = [p for p in soup('p') if p.get('id')]\n",
    "paragraphs_with_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontra tags com uma class específica:\n",
    "\n",
    "important_paragraphs = soup('p', {'id' : 'p1'}) \n",
    "important_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_paragraphs2 = soup('p', 'important')\n",
    "important_paragraphs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_paragraphs3 = [p for p in soup('p') if 'important' in p.get('class', [])]\n",
    "important_paragraphs3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos fazer muita coisa com esses poucos recursos. Para executar ações mais complicadas (ou por curiosidade), \n",
    "confira a documentação (https://www.crummy.com/software/BeautifulSoup/bs4/doc/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
